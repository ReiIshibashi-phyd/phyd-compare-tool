{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV比較ツール\n",
    "## キー突合 + 全項目比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# フォルダパス\n",
    "BEFORE_FOLDER = '../data/before'\n",
    "AFTER_FOLDER = '../data/after'\n",
    "\n",
    "# 大容量対応設定\n",
    "CHUNK_SIZE = 5000  # チャンクサイズ（行数）\n",
    "MEMORY_LIMIT_MB = 500  # メモリ制限（MB）\n",
    "\n",
    "# 設定ファイル読み込み\n",
    "def load_config(config_file='../config.txt'):\n",
    "    config = {'file_settings': {}}\n",
    "    try:\n",
    "        with open(config_file, 'r', encoding='utf-8') as f:\n",
    "            current_section = None\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    if '=' in line:\n",
    "                        if ' = ' in line:\n",
    "                            key, value = line.split(' = ', 1)\n",
    "                        else:\n",
    "                            parts = line.split('=')\n",
    "                            key = parts[0].strip()\n",
    "                            value = parts[1].strip() if len(parts) > 1 else ''\n",
    "                        if key == 'FILE_SETTINGS':\n",
    "                            current_section = 'file_settings'\n",
    "                        elif key.startswith('DEFAULT_'):\n",
    "                            config[key] = value\n",
    "                        else:\n",
    "                            config[key] = value\n",
    "                    elif current_section == 'file_settings' and ':' in line:\n",
    "                        parts = line.split(':')\n",
    "                        if len(parts) >= 2:\n",
    "                            filename = parts[0]\n",
    "                            key_columns = [k.strip() for k in parts[1].split(',') if k.strip()]\n",
    "                            ignore_columns = []\n",
    "                            if len(parts) > 2 and parts[2]:\n",
    "                                ignore_columns = [i.strip() for i in parts[2].split(';') if i.strip()]\n",
    "                            config['file_settings'][filename] = {\n",
    "                                'key_columns': key_columns,\n",
    "                                'ignore_columns': ignore_columns\n",
    "                            }\n",
    "        print(f'設定ファイルを読み込みました: {config_file}')\n",
    "    except FileNotFoundError:\n",
    "        print(f'設定ファイルが見つかりません: {config_file}')\n",
    "        config = {'DEFAULT_KEY_COLUMNS': 'id', 'DEFAULT_IGNORE_COLUMNS': '', 'file_settings': {}}\n",
    "    return config\n",
    "\n",
    "def get_file_config(filename, config):\n",
    "    if filename in config['file_settings']:\n",
    "        return config['file_settings'][filename]\n",
    "    \n",
    "    default_keys = config.get('DEFAULT_KEY_COLUMNS', 'id')\n",
    "    default_ignore = config.get('DEFAULT_IGNORE_COLUMNS', '')\n",
    "    \n",
    "    key_columns = [k.strip() for k in default_keys.split(',') if k.strip()]\n",
    "    ignore_columns = []\n",
    "    if default_ignore and default_ignore not in ['', 'なし', 'NONE', 'none']:\n",
    "        ignore_columns = [i.strip() for i in default_ignore.split(',') if i.strip()]\n",
    "    \n",
    "    return {'key_columns': key_columns, 'ignore_columns': ignore_columns}\n",
    "\n",
    "# ファイル一覧取得\n",
    "def get_csv_files(folder_path):\n",
    "    path = Path(folder_path)\n",
    "    return [f.name for f in path.glob('*.csv')]\n",
    "\n",
    "before_files = get_csv_files(BEFORE_FOLDER)\n",
    "after_files = get_csv_files(AFTER_FOLDER)\n",
    "common_files = list(set(before_files) & set(after_files))\n",
    "\n",
    "print(f'Beforeフォルダのファイル: {before_files}')\n",
    "print(f'Afterフォルダのファイル: {after_files}')\n",
    "print(f'比較対象ファイル: {common_files}')\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "if common_files:\n",
    "    print('\\n設定内容:')\n",
    "    for filename in common_files:\n",
    "        file_config = get_file_config(filename, config)\n",
    "        print(f'{filename}: キー={file_config[\"key_columns\"]}, 無視={file_config[\"ignore_columns\"]}')\n",
    "else:\n",
    "    print('比較対象ファイルがありません')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 大容量対応比較処理関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_info(file_path):\n",
    "    \"\"\"ファイル情報を取得\"\"\"\n",
    "    file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
    "    \n",
    "    # 行数をカウント\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        row_count = sum(1 for _ in f) - 1  # ヘッダー除く\n",
    "    \n",
    "    return {'size_mb': file_size, 'rows': row_count}\n",
    "\n",
    "def compare_csv_large(baseline_path, candidate_path, key_columns, ignore_columns=None):\n",
    "    \"\"\"大容量ファイル対応の比較処理\"\"\"\n",
    "    if ignore_columns is None:\n",
    "        ignore_columns = []\n",
    "    \n",
    "    print(\"ファイル情報を取得中...\")\n",
    "    baseline_info = get_file_info(baseline_path)\n",
    "    candidate_info = get_file_info(candidate_path)\n",
    "    \n",
    "    print(f\"Baseline: {baseline_info['rows']:,}行, {baseline_info['size_mb']:.1f}MB\")\n",
    "    print(f\"Candidate: {candidate_info['rows']:,}行, {candidate_info['size_mb']:.1f}MB\")\n",
    "    \n",
    "    total_size = baseline_info['size_mb'] + candidate_info['size_mb']\n",
    "    \n",
    "    if total_size > MEMORY_LIMIT_MB:\n",
    "        print(f\"大容量ファイル検出（{total_size:.1f}MB > {MEMORY_LIMIT_MB}MB）\")\n",
    "        print(\"チャンク処理を実行します...\")\n",
    "        return compare_csv_chunked(baseline_path, candidate_path, key_columns, ignore_columns)\n",
    "    else:\n",
    "        print(\"通常処理を実行します...\")\n",
    "        return compare_csv_normal(baseline_path, candidate_path, key_columns, ignore_columns)\n",
    "\n",
    "def compare_csv_normal(baseline_path, candidate_path, key_columns, ignore_columns):\n",
    "    \"\"\"通常の比較処理\"\"\"\n",
    "    baseline_df = pd.read_csv(baseline_path)\n",
    "    candidate_df = pd.read_csv(candidate_path)\n",
    "    \n",
    "    return process_comparison(baseline_df, candidate_df, key_columns, ignore_columns)\n",
    "\n",
    "def compare_csv_chunked(baseline_path, candidate_path, key_columns, ignore_columns):\n",
    "    \"\"\"チャンク処理による比較\"\"\"\n",
    "    # キー列のみでインデックス作成\n",
    "    print(\"キーインデックスを作成中...\")\n",
    "    baseline_keys = create_key_index(baseline_path, key_columns)\n",
    "    candidate_keys = create_key_index(candidate_path, key_columns)\n",
    "    \n",
    "    print(f\"Baselineキー数: {len(baseline_keys):,}\")\n",
    "    print(f\"Candidateキー数: {len(candidate_keys):,}\")\n",
    "    \n",
    "    # 差分キーを特定\n",
    "    deleted_keys = baseline_keys - candidate_keys\n",
    "    added_keys = candidate_keys - baseline_keys\n",
    "    common_keys = baseline_keys & candidate_keys\n",
    "    \n",
    "    print(f\"削除: {len(deleted_keys):,}, 追加: {len(added_keys):,}, 共通: {len(common_keys):,}\")\n",
    "    \n",
    "    diff_records = []\n",
    "    \n",
    "    # 削除・追加レコード\n",
    "    for key in deleted_keys:\n",
    "        diff_records.append({\n",
    "            'key': key,\n",
    "            'diff_type': 'DELETED',\n",
    "            'column': None,\n",
    "            'baseline_value': None,\n",
    "            'candidate_value': None\n",
    "        })\n",
    "    \n",
    "    for key in added_keys:\n",
    "        diff_records.append({\n",
    "            'key': key,\n",
    "            'diff_type': 'ADDED',\n",
    "            'column': None,\n",
    "            'baseline_value': None,\n",
    "            'candidate_value': None\n",
    "        })\n",
    "    \n",
    "    # 共通キーの詳細比較（チャンク処理）\n",
    "    if common_keys:\n",
    "        print(\"詳細比較を実行中...\")\n",
    "        modified_records = compare_common_keys_chunked(\n",
    "            baseline_path, candidate_path, common_keys, key_columns, ignore_columns\n",
    "        )\n",
    "        diff_records.extend(modified_records)\n",
    "    \n",
    "    return pd.DataFrame(diff_records)\n",
    "\n",
    "def create_key_index(file_path, key_columns):\n",
    "    \"\"\"キーインデックスを作成\"\"\"\n",
    "    keys = set()\n",
    "    \n",
    "    for chunk in pd.read_csv(file_path, chunksize=CHUNK_SIZE, usecols=key_columns):\n",
    "        if len(key_columns) > 1:\n",
    "            chunk_keys = chunk[key_columns].astype(str).agg('_'.join, axis=1)\n",
    "        else:\n",
    "            chunk_keys = chunk[key_columns[0]].astype(str)\n",
    "        \n",
    "        keys.update(chunk_keys.tolist())\n",
    "        gc.collect()\n",
    "    \n",
    "    return keys\n",
    "\n",
    "def compare_common_keys_chunked(baseline_path, candidate_path, common_keys, key_columns, ignore_columns):\n",
    "    \"\"\"共通キーの詳細比較（チャンク処理）\"\"\"\n",
    "    modified_records = []\n",
    "    processed_keys = set()\n",
    "    \n",
    "    # Baselineをチャンクで読み込み\n",
    "    baseline_chunks = pd.read_csv(baseline_path, chunksize=CHUNK_SIZE)\n",
    "    \n",
    "    for baseline_chunk in tqdm(baseline_chunks, desc=\"比較処理\"):\n",
    "        # キー作成\n",
    "        if len(key_columns) > 1:\n",
    "            baseline_chunk['_key'] = baseline_chunk[key_columns].astype(str).agg('_'.join, axis=1)\n",
    "        else:\n",
    "            baseline_chunk['_key'] = baseline_chunk[key_columns[0]].astype(str)\n",
    "        \n",
    "        # 共通キーのみ抽出\n",
    "        baseline_common = baseline_chunk[baseline_chunk['_key'].isin(common_keys)]\n",
    "        \n",
    "        if len(baseline_common) == 0:\n",
    "            continue\n",
    "        \n",
    "        # 対応するCandidateデータを取得\n",
    "        target_keys = baseline_common['_key'].tolist()\n",
    "        candidate_data = get_candidate_data_by_keys(candidate_path, target_keys, key_columns)\n",
    "        \n",
    "        # 詳細比較\n",
    "        chunk_diffs = compare_chunk_details(baseline_common, candidate_data, key_columns, ignore_columns)\n",
    "        modified_records.extend(chunk_diffs)\n",
    "        \n",
    "        processed_keys.update(target_keys)\n",
    "        gc.collect()\n",
    "    \n",
    "    return modified_records\n",
    "\n",
    "def get_candidate_data_by_keys(candidate_path, target_keys, key_columns):\n",
    "    \"\"\"指定キーのCandidateデータを取得\"\"\"\n",
    "    candidate_data = []\n",
    "    \n",
    "    for chunk in pd.read_csv(candidate_path, chunksize=CHUNK_SIZE):\n",
    "        if len(key_columns) > 1:\n",
    "            chunk['_key'] = chunk[key_columns].astype(str).agg('_'.join, axis=1)\n",
    "        else:\n",
    "            chunk['_key'] = chunk[key_columns[0]].astype(str)\n",
    "        \n",
    "        matching_rows = chunk[chunk['_key'].isin(target_keys)]\n",
    "        if len(matching_rows) > 0:\n",
    "            candidate_data.append(matching_rows)\n",
    "    \n",
    "    return pd.concat(candidate_data, ignore_index=True) if candidate_data else pd.DataFrame()\n",
    "\n",
    "def compare_chunk_details(baseline_chunk, candidate_chunk, key_columns, ignore_columns):\n",
    "    \"\"\"チャンク内の詳細比較\"\"\"\n",
    "    if len(candidate_chunk) == 0:\n",
    "        return []\n",
    "    \n",
    "    baseline_indexed = baseline_chunk.set_index('_key')\n",
    "    candidate_indexed = candidate_chunk.set_index('_key')\n",
    "    \n",
    "    compare_columns = [col for col in baseline_chunk.columns \n",
    "                      if col not in key_columns and col not in ignore_columns and col != '_key']\n",
    "    \n",
    "    diff_records = []\n",
    "    \n",
    "    for key in baseline_indexed.index:\n",
    "        if key not in candidate_indexed.index:\n",
    "            continue\n",
    "        \n",
    "        baseline_row = baseline_indexed.loc[key]\n",
    "        candidate_row = candidate_indexed.loc[key]\n",
    "        \n",
    "        for col in compare_columns:\n",
    "            baseline_val = baseline_row[col]\n",
    "            candidate_val = candidate_row[col]\n",
    "            \n",
    "            if pd.isna(baseline_val) and pd.isna(candidate_val):\n",
    "                continue\n",
    "            \n",
    "            if baseline_val != candidate_val:\n",
    "                diff_records.append({\n",
    "                    'key': key,\n",
    "                    'diff_type': 'MODIFIED',\n",
    "                    'column': col,\n",
    "                    'baseline_value': baseline_val,\n",
    "                    'candidate_value': candidate_val\n",
    "                })\n",
    "    \n",
    "    return diff_records\n",
    "\n",
    "def process_comparison(baseline_df, candidate_df, key_columns, ignore_columns):\n",
    "    \"\"\"通常の比較処理（既存ロジック）\"\"\"\n",
    "    if len(key_columns) > 1:\n",
    "        baseline_df = baseline_df.copy()\n",
    "        candidate_df = candidate_df.copy()\n",
    "        combined_key = '_'.join(key_columns)\n",
    "        baseline_df[combined_key] = baseline_df[key_columns].astype(str).agg('_'.join, axis=1)\n",
    "        candidate_df[combined_key] = candidate_df[key_columns].astype(str).agg('_'.join, axis=1)\n",
    "        key_column = combined_key\n",
    "    else:\n",
    "        key_column = key_columns[0]\n",
    "    \n",
    "    baseline_indexed = baseline_df.set_index(key_column)\n",
    "    candidate_indexed = candidate_df.set_index(key_column)\n",
    "    \n",
    "    compare_columns = [col for col in baseline_df.columns \n",
    "                      if col not in key_columns and col not in ignore_columns and col != key_column]\n",
    "    \n",
    "    diff_records = []\n",
    "    \n",
    "    # 削除・追加・変更の検出\n",
    "    missing_keys = baseline_indexed.index.difference(candidate_indexed.index)\n",
    "    extra_keys = candidate_indexed.index.difference(baseline_indexed.index)\n",
    "    common_keys = baseline_indexed.index.intersection(candidate_indexed.index)\n",
    "    \n",
    "    for key in missing_keys:\n",
    "        diff_records.append({\n",
    "            'key': key, 'diff_type': 'DELETED', 'column': None,\n",
    "            'baseline_value': None, 'candidate_value': None\n",
    "        })\n",
    "    \n",
    "    for key in extra_keys:\n",
    "        diff_records.append({\n",
    "            'key': key, 'diff_type': 'ADDED', 'column': None,\n",
    "            'baseline_value': None, 'candidate_value': None\n",
    "        })\n",
    "    \n",
    "    for key in common_keys:\n",
    "        baseline_row = baseline_indexed.loc[key]\n",
    "        candidate_row = candidate_indexed.loc[key]\n",
    "        \n",
    "        for col in compare_columns:\n",
    "            baseline_val = baseline_row[col]\n",
    "            candidate_val = candidate_row[col]\n",
    "            \n",
    "            if pd.isna(baseline_val) and pd.isna(candidate_val):\n",
    "                continue\n",
    "            \n",
    "            if baseline_val != candidate_val:\n",
    "                diff_records.append({\n",
    "                    'key': key, 'diff_type': 'MODIFIED', 'column': col,\n",
    "                    'baseline_value': baseline_val, 'candidate_value': candidate_val\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(diff_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ファイル比較実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_files_large(filename):\n",
    "    \"\"\"大容量対応ファイル比較\"\"\"\n",
    "    before_path = os.path.join(BEFORE_FOLDER, filename)\n",
    "    after_path = os.path.join(AFTER_FOLDER, filename)\n",
    "    \n",
    "    print(f'\\n=== {filename} の比較（大容量対応） ===')\n",
    "    \n",
    "    file_config = get_file_config(filename, config)\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    diff_df = compare_csv_large(before_path, after_path, file_config['key_columns'], file_config['ignore_columns'])\n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    processing_time = (end_time - start_time).total_seconds()\n",
    "    print(f'処理時間: {processing_time:.1f}秒')\n",
    "    print(f'検出された差分: {len(diff_df):,} 件')\n",
    "    \n",
    "    if len(diff_df) > 0:\n",
    "        # サマリー表示\n",
    "        print('\\n差分サマリー:')\n",
    "        summary = diff_df['diff_type'].value_counts()\n",
    "        for diff_type, count in summary.items():\n",
    "            print(f'  {diff_type}: {count:,}件')\n",
    "        \n",
    "        # 最初の10件を表示\n",
    "        print('\\n差分サンプル（最初の10件）:')\n",
    "        display(diff_df.head(10))\n",
    "        \n",
    "        # レポート出力\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        output_filename = f'{filename.replace(\".csv\", \"\")}_diff_{timestamp}.csv'\n",
    "        output_path = f'../output/{output_filename}'\n",
    "        \n",
    "        print(f'\\n差分レポートを出力中... ({len(diff_df):,}件)')\n",
    "        diff_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        # 統計レポート出力\n",
    "        stats_filename = f'{filename.replace(\".csv\", \"\")}_stats_{timestamp}.txt'\n",
    "        stats_path = f'../output/{stats_filename}'\n",
    "        \n",
    "        with open(stats_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(f'=== {filename} 比較統計レポート ===\\n\\n')\n",
    "            f.write(f'処理時間: {processing_time:.1f}秒\\n')\n",
    "            f.write(f'総差分件数: {len(diff_df):,}件\\n\\n')\n",
    "            f.write('差分タイプ別件数:\\n')\n",
    "            for diff_type, count in summary.items():\n",
    "                f.write(f'  {diff_type}: {count:,}件\\n')\n",
    "            \n",
    "            if 'MODIFIED' in summary:\n",
    "                modified_df = diff_df[diff_df['diff_type'] == 'MODIFIED']\n",
    "                column_counts = modified_df['column'].value_counts()\n",
    "                f.write('\\n変更項目別件数:\\n')\n",
    "                for col, count in column_counts.head(10).items():\n",
    "                    f.write(f'  {col}: {count:,}件\\n')\n",
    "        \n",
    "        print(f'差分レポート: {output_path}')\n",
    "        print(f'統計レポート: {stats_path}')\n",
    "    else:\n",
    "        print('差分はありません')\n",
    "    \n",
    "    # メモリクリア\n",
    "    del diff_df\n",
    "    gc.collect()\n",
    "    \n",
    "    return processing_time\n",
    "\n",
    "# 全ファイル比較実行\n",
    "total_start = datetime.now()\n",
    "processing_times = {}\n",
    "\n",
    "for filename in common_files:\n",
    "    processing_time = compare_files_large(filename)\n",
    "    processing_times[filename] = processing_time\n",
    "\n",
    "total_end = datetime.now()\n",
    "total_time = (total_end - total_start).total_seconds()\n",
    "\n",
    "print(f'\\n=== 全体処理完了 ===')\n",
    "print(f'総処理時間: {total_time:.1f}秒')\n",
    "for filename, time in processing_times.items():\n",
    "    print(f'{filename}: {time:.1f}秒')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
